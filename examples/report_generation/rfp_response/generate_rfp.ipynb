{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e8f1c8-44e8-461d-9a12-13e714448fa1",
   "metadata": {},
   "source": [
    "# RFP Response Generation\n",
    "\n",
    "Given template, given context, generate hypothetical RFP response report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310efa-1422-4214-b0bf-41b6e163fac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download JEDI Cloud RFP Template\n",
    "!wget \"https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\" -O data/jedi_cloud_rfp.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd474cc-2f85-4dc2-900e-4ec203e11d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# microsoft annual report\n",
    "!wget \"https://www.dropbox.com/scl/fi/4v5dx8dc9yqc8k0yw5g4h/msft_10k_2024.pdf?rlkey=jdyfrsoyb18ztlq5msunmibns&st=9w6bdyvn&dl=1\" -O data/msft_10k_2024.pdf\n",
    "# !wget \"https://microsoft.gcs-web.com/static-files/1c864583-06f7-40cc-a94d-d11400c83cc8\" -O data/msft_10k_2024.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ee29f-cf2b-4cad-9e62-b41cbda32b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# azure wikipedia page\n",
    "!wget \"https://www.dropbox.com/scl/fi/7waur8ravmve3fe8nej0k/azure_wiki.pdf?rlkey=icru2w64oylx1p76ftt6y9irv&st=fr87vxob&dl=1\" -O data/azure_wiki.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc26807-d17c-4b57-b802-1e01bf652530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# azure government slide deck\n",
    "!wget \"https://cdn.ymaws.com/flclerks.site-ym.com/resource/resmgr/2017_Fall_Conf/Presentations/2018-10-12_FCCC_Microsoft_Az.pdf\" -O data/azure_gov.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138d82c-1c97-415f-9961-a65bc000df98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# microsoft cybersecurity capabilities\n",
    "!wget \"https://www.dropbox.com/scl/fi/qh00xz29rlom4md8ce675/microsoft_ddr.pdf?rlkey=d868nbnsu1ng41y1chw69y64b&st=24iqemb1&dl=1\" -O data/msft_ddr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7137b3-5b37-4e52-bc46-b994693d2664",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f28c6a-cb5e-4c16-bdc7-a69817fc4c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cddd64-b886-4b0a-b010-2c0168b42147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "# use our multimodal models for extractions\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242a7dea-db8f-4d6d-bc1e-33bef6faaeae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "files = [\n",
    "    \"azure_gov.pdf\",\n",
    "    \"azure_wiki.pdf\",\n",
    "    # \"jedi_cloud_rfp.pdf\",\n",
    "    \"msft_10k_2024.pdf\",\n",
    "    \"msft_ddr.pdf\"\n",
    "]\n",
    "\n",
    "\n",
    "file_dicts = {}\n",
    "\n",
    "for f in files:\n",
    "    file_base = Path(f).stem\n",
    "    full_file_path = str(Path(data_dir) / f)\n",
    "    # md_json_objs = parser.get_json_result(full_file_path)\n",
    "    # json_dicts = md_json_objs[0][\"pages\"]\n",
    "    \n",
    "    file_docs = parser.load_data(full_file_path)\n",
    "\n",
    "    # image_path = str(Path(out_image_dir) / file_base)\n",
    "    # image_dicts = parser.get_images(md_json_objs, download_path=image_path)\n",
    "    file_dicts[f] = {\n",
    "        \"file_path\": full_file_path,\n",
    "        \"docs\": file_docs\n",
    "        # \"file_path\": full_file_path,\n",
    "        # \"json_dicts\": json_dicts,\n",
    "        # \"image_path\": image_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5000db-d5ca-4522-8dfa-bc64567b1884",
   "metadata": {},
   "source": [
    "### Build Indexes\n",
    "\n",
    "Once the text nodes are ready, we feed into our vector store, which will index these nodes into Chroma (you're welcome to use our other 40+ vector store integrations if you'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a2cb3-d21b-4ccf-81a0-1a83d0514a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "persist_dir = \"storage_rfp_chroma\"\n",
    "\n",
    "vector_store = ChromaVectorStore.from_params(\n",
    "    collection_name=\"rfp_docs\",\n",
    "    persist_dir=persist_dir\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f44aa-8dfa-4267-9489-d876ce056931",
   "metadata": {},
   "source": [
    "**NOTE**: Don't run if you've already inserted the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216cfef-7225-4acd-97c9-5e957afb528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.clear()\n",
    "all_nodes = [c for d in file_dicts.values() for c in d[\"docs\"]]\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4446-c477-4261-9747-c5294b0a54e9",
   "metadata": {},
   "source": [
    "### Define Retrievers\n",
    "\n",
    "Define retrievers, one for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbac9ab-e3e2-448f-9e74-ad995415fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "\n",
    "# function tools\n",
    "def chunk_retriever_fn_factory(file: str):\n",
    "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(\n",
    "                key=\"file_name\", operator=FilterOperator.EQ, value=file\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    def chunk_retriever_fn(query: str) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieves a small set of relevant document chunks from the corpus.\n",
    "\n",
    "        ONLY use for research questions that want to look up specific facts from the knowledge corpus,\n",
    "        and don't need entire documents.\n",
    "\n",
    "        \"\"\"\n",
    "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
    "        nodes = retriever.retrieve(query)\n",
    "        return nodes\n",
    "    \n",
    "    return chunk_retriever_fn\n",
    "\n",
    "# generate tools \n",
    "tools = []\n",
    "for f in files:\n",
    "    tools.append(FunctionTool.from_defaults(fn=chunk_retriever_fn_factory(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebbad-3200-4818-aa48-705eda21503e",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "\n",
    "The user specifies an RFP document as input. \n",
    "\n",
    "Let's build a workflow that can iterate through the extracted keys/questions from the RFP, and fill them out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2c0d0-415d-4568-936b-a8c07bf629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_docs = parser.load_data(Path(data_dir) / \"jedi_cloud_rfp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740535e8-714b-4744-a515-5007834eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# this is the research agent's system prompt, tasked with answering a specific question\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
    "You are given a specific form key/question. Think step-by-step and use the existing set of tools to help answer the question.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the prompt tasked with extracting information from an RFP file. \n",
    "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
    "You are provided an entire RFP document, or a large subsection from it. \n",
    "\n",
    "We wish to generate a response to the RFP in a way that adheres to the instructions within the RFP, \\\n",
    "including the specific sections that an RFP response should contain, and the content that would need to go \\\n",
    "into each section.\n",
    "\n",
    "Your task is to extract out a list of \"questions\", where each question corresponds to a specific section that is required in the RFP response.\n",
    "Put another way, after we extract out the questions we will go through each question and answer each one \\\n",
    "with our downstream research assistant, and the combined\n",
    "question:answer pairs will constitute the full RFP response.\n",
    "\n",
    "- Make sure the questions are comprehensive and adheres to the RFP requirements.\n",
    "- Make sure each question is descriptive - this gives our downstream assistant context to fill out the value for that question \n",
    "- Extract out all the questions as a list of strings.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class OutputQuestions(BaseModel):\n",
    "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class OutputTemplateEvent(Event):\n",
    "    doc: List[Document]\n",
    "\n",
    "\n",
    "class QuestionsExtractedEvent(Event):\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class HandleQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class QuestionAnsweredEvent(Event):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "class CollectedAnswersEvent(Event):\n",
    "    combined_answers: str\n",
    "\n",
    "class RFPWorkflow(Workflow):\n",
    "    \"\"\"RFP workflow.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        tools,\n",
    "        parser: LlamaParse,\n",
    "        llm: LLM | None = None,\n",
    "        similarity_top_k: int = 20,\n",
    "        output_dir: str = \"data_out_rfp\",\n",
    "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.tools = tools\n",
    "        \n",
    "        self.parser = parser\n",
    "        \n",
    "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # initialize a Function Calling \"research\" agent where given a task, it can pull responses from relevant tools \n",
    "        self.research_agent = FunctionCallingAgentWorker.from_tools(\n",
    "            tools, llm=llm, verbose=True, system_prompt=agent_system_prompt\n",
    "        ).as_agent()\n",
    "        \n",
    "    @step\n",
    "    async def parse_output_template(self, ctx: Context, ev: StartEvent) -> OutputTemplateEvent:\n",
    "        # load output template file \n",
    "        docs = await self.parser.aload_data(ev.rfp_template_path)\n",
    "        # save output template to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/output_template.json\", \"w\") as f:\n",
    "            for doc in docs:\n",
    "                f.write(doc.model_dump_json())\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        await ctx.set(\"output_template\", docs)\n",
    "        return OutputTemplateEvent(doc=docs)\n",
    "    \n",
    "    @step\n",
    "    async def extract_questions(self, ctx: Context, ev: OutputTemplateEvent) -> HandleQuestionEvent:\n",
    "        doc = ev.doc\n",
    "        try: \n",
    "            prompt = PromptTemplate(template=EXTRACT_KEYS_PROMPT)\n",
    "            output_qs = self.llm.structured_predict(\n",
    "                OutputQuestions, prompt, context=page.text\n",
    "            )\n",
    "        except Exception as e:\n",
    "            _logger.error(f\"Error extracting questions from page: {page.text}\")\n",
    "            _logger.error(e)\n",
    "\n",
    "\n",
    "        # save all_questions to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/all_keys.json\", \"w\") as f:\n",
    "            f.write(json.dumps(output_qs))\n",
    "        \n",
    "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
    "\n",
    "        for question in output_qs:\n",
    "            ctx.send_event(HandleQuestionEvent(question=question))\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @step\n",
    "    async def handle_question(self, ev: HandleQuestionEvent) -> QuestionAnsweredEvent:\n",
    "        question = ev.question\n",
    "        \n",
    "        # ensure the agent's memory is cleared \n",
    "        self.research_agent.reset()\n",
    "        response = self.research_agent.query(question)\n",
    "        \n",
    "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(self, ctx: Context, ev: QuestionAnsweredEvent) -> CollectedAnswersEvent:\n",
    "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
    "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "        \n",
    "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
    "        # save combined_answers to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/combined_answers.json\", \"w\") as f:\n",
    "            f.write(combined_answers)\n",
    "\n",
    "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
    "\n",
    "    @step\n",
    "    async def generate_output(self, ctx: Context, ev: CollectedAnswersEvent) -> StopEvent:\n",
    "        output_template = await ctx.get(\"output_template\")\n",
    "        output_template = \"\\n\".join([doc.get_content('none') for doc in output_template])\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=GENERATE_OUTPUT_PROMPT,\n",
    "        )\n",
    "        final_output = self.llm.predict(prompt, output_template=output_template, answers=ev.combined_answers)\n",
    "        # save final_output to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
    "            f.write(final_output)\n",
    "\n",
    "        return StopEvent(result=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895c3b1-6ea1-41c3-bcf9-e42c2a4beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = RFPWorkflow(\n",
    "    tools,\n",
    "    parser=parser,\n",
    "    llm=llm\n",
    "    verbose=True,\n",
    "    timeout=60.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2465b-62f7-4afc-bc18-6ab3fbe5bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the agent\n",
    "response = workflow.run(str(Path(data_dir) / \"jedi_cloud_rfp.pdf\"))\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_parse",
   "language": "python",
   "name": "llama_parse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
