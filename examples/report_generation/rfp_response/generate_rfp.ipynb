{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e8f1c8-44e8-461d-9a12-13e714448fa1",
   "metadata": {},
   "source": [
    "# RFP Response Generation\n",
    "\n",
    "Given template, given context, generate hypothetical RFP response report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310efa-1422-4214-b0bf-41b6e163fac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download JEDI Cloud RFP Template\n",
    "!wget \"https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\" -O data/jedi_cloud_rfp.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd474cc-2f85-4dc2-900e-4ec203e11d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# microsoft annual report\n",
    "!wget \"https://www.dropbox.com/scl/fi/4v5dx8dc9yqc8k0yw5g4h/msft_10k_2024.pdf?rlkey=jdyfrsoyb18ztlq5msunmibns&st=9w6bdyvn&dl=1\" -O data/msft_10k_2024.pdf\n",
    "# !wget \"https://microsoft.gcs-web.com/static-files/1c864583-06f7-40cc-a94d-d11400c83cc8\" -O data/msft_10k_2024.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ee29f-cf2b-4cad-9e62-b41cbda32b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# azure wikipedia page\n",
    "!wget \"https://www.dropbox.com/scl/fi/7waur8ravmve3fe8nej0k/azure_wiki.pdf?rlkey=icru2w64oylx1p76ftt6y9irv&st=fr87vxob&dl=1\" -O data/azure_wiki.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc26807-d17c-4b57-b802-1e01bf652530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# azure government slide deck\n",
    "!wget \"https://cdn.ymaws.com/flclerks.site-ym.com/resource/resmgr/2017_Fall_Conf/Presentations/2018-10-12_FCCC_Microsoft_Az.pdf\" -O data/azure_gov.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138d82c-1c97-415f-9961-a65bc000df98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# microsoft cybersecurity capabilities\n",
    "!wget \"https://www.dropbox.com/scl/fi/qh00xz29rlom4md8ce675/microsoft_ddr.pdf?rlkey=d868nbnsu1ng41y1chw69y64b&st=24iqemb1&dl=1\" -O data/msft_ddr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7137b3-5b37-4e52-bc46-b994693d2664",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f28c6a-cb5e-4c16-bdc7-a69817fc4c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cddd64-b886-4b0a-b010-2c0168b42147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "# use our multimodal models for extractions\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f85d79c-8835-4684-9883-f6342ceb44b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = \"data\"\n",
    "files = [\n",
    "    \"azure_gov.pdf\",\n",
    "    \"azure_wiki.pdf\",\n",
    "    # \"jedi_cloud_rfp.pdf\",\n",
    "    \"msft_10k_2024.pdf\",\n",
    "    \"msft_ddr.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cc182-663a-4b30-9a70-5af22acbe83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_dicts = {}\n",
    "\n",
    "for f in files:\n",
    "    file_base = Path(f).stem\n",
    "    full_file_path = str(Path(data_dir) / f)\n",
    "    # md_json_objs = parser.get_json_result(full_file_path)\n",
    "    # json_dicts = md_json_objs[0][\"pages\"]\n",
    "    \n",
    "    file_docs = parser.load_data(full_file_path)\n",
    "    \n",
    "    # attach metadata\n",
    "    for idx, d in enumerate(file_docs):\n",
    "        d.metadata[\"file_path\"] = f\n",
    "        d.metadata[\"page_num\"] = idx + 1\n",
    "\n",
    "    # image_path = str(Path(out_image_dir) / file_base)\n",
    "    # image_dicts = parser.get_images(md_json_objs, download_path=image_path)\n",
    "    file_dicts[f] = {\n",
    "        \"file_path\": full_file_path,\n",
    "        \"docs\": file_docs\n",
    "        # \"file_path\": full_file_path,\n",
    "        # \"json_dicts\": json_dicts,\n",
    "        # \"image_path\": image_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dce7d1-558b-4416-9a14-65080d0f6979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # TMP\n",
    "# for f in files:\n",
    "#     # attach metadata\n",
    "#     for idx, d in enumerate(file_dicts[f][\"docs\"]):\n",
    "#         d.metadata[\"file_path\"] = f\n",
    "#         d.metadata[\"page_num\"] = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046efc75-a204-4f06-864f-fc176b9eb8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # TMP \n",
    "# tmp = parser.load_data(\"data/azure_gov.pdf\")\n",
    "# print(tmp[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f15aea4-4a2f-494e-ac32-c16f4a82b6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(file_dicts.keys())\n",
    "\n",
    "# file_dicts[\"azure_gov.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "684864e1-d751-4a34-ae0e-51296ed31493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(file_dicts, open(\"tmp_file_dicts.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a6849b-4572-4315-b7d5-77ad3b7ec351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_dicts = pickle.load(open(\"tmp_file_dicts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5000db-d5ca-4522-8dfa-bc64567b1884",
   "metadata": {},
   "source": [
    "### Build Indexes\n",
    "\n",
    "Once the text nodes are ready, we feed into our vector store, which will index these nodes into Chroma (you're welcome to use our other 40+ vector store integrations if you'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a31409f-815d-4569-8b74-60fcec5af211",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "101920ab-4054-4164-9f29-c3c9025c13bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run if you want to recreate the index \n",
    "!rm -rf storage_rfp_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b1a2cb3-d21b-4ccf-81a0-1a83d0514a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "persist_dir = \"storage_rfp_chroma\"\n",
    "\n",
    "vector_store = ChromaVectorStore.from_params(\n",
    "    collection_name=\"rfp_docs\",\n",
    "    persist_dir=persist_dir\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf51a9bd-1ea4-4fb1-9756-5ce07e227dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: storage_rfp_chroma: File exists\n"
     ]
    }
   ],
   "source": [
    "# !chmod 777 storage_rfp_chroma\n",
    "!mkdir storage_rfp_chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f44aa-8dfa-4267-9489-d876ce056931",
   "metadata": {},
   "source": [
    "**NOTE**: Don't run if you've already inserted the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fcbaf7-9552-4ddb-9d7f-c499126c8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.clear()\n",
    "all_nodes = [c for d in file_dicts.values() for c in d[\"docs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2beab03a-e998-4fb8-b37f-c72140666874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'azure_gov.pdf', 'page_num': 1}\n"
     ]
    }
   ],
   "source": [
    "print(all_nodes[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245b415a-f737-4745-99c0-d4197bb9f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: d7d976fa-be46-4984-966d-afb0478cbe26\n",
      "Insert of existing embedding ID: d7d976fa-be46-4984-966d-afb0478cbe26\n"
     ]
    }
   ],
   "source": [
    "index.insert_nodes(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe0fdaf6-16fe-4976-9a6e-072143fed795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='a2bd510a-2756-4c54-8d29-6186b2e24c93', embedding=None, metadata={'file_path': 'msft_ddr.pdf', 'page_num': 100}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='# Responding with breakthrough innovation continued\\n\\nExperiences based on large language models, like ChatGPT, have taken the world by storm in the last year. This is in part because they can draw upon a vast store of data, leveraging the massive computing power available today in the cloud. But what I think is more exciting is the real, tangible impact that technology like this can drive. AI, together with the power of cloud and machine learning, has enormous potential. Much like we led the charge on password spray detection, two-factor authentication enforcement, and managed device health, we have an opportunity to demonstrate how responsible AI has the potential to positively transform the security landscape.\\n\\nAt Microsoft, we are developing first- and third-party solutions for our ever-increasing number of enterprise, government, and consumer customers and partners. We have seen developer activity double in the last three years, and it is up by over 31 percent in the last year alone. This trend will accelerate as developers adopt AI powered development tools like GitHub Copilot. This will require a commensurate increase in threat models, code reviews, compliance attestations, and app/ infrastructure assurance to secure resilience.\\n\\nAn important contribution we can make is to continue to evolve our Security Development Lifecycle (SDL) rules and engineering compliance. This will ensure continued focus on secure engineering practices.\\n\\nWe recently simplified, updated, and automated our SDL and Operational Security Assurance requirements into a single standard. We will increase our compliance with the modernized SDL through enhanced training, automation, and reporting.\\n\\nWe will also deploy Security CoPilot—our new AI powered incident response assistant—across our incident response teams, so that we can both gain the benefit of AI in addressing security incidents, and so we can improve this valuable new capability by providing our development teams with feedback based on our real-world experience.\\n\\nBased on actions needed to meet the growing threat landscape, our approach for the next year will focus on bringing to bear AI in combating threats while also embracing the three SDL principles of Secure by Design, Secure by Default, and Secure in Deployment (SD3). While it may sound simple, this will require all of us to prioritize and collaborate to successfully execute across everything we do, every day.\\n\\nBret Arsenault\\nChief Information Security Officer\\n\\n## We have defined three priority areas in which we will invest to ensure that we embed SD3:\\n\\n1. Be Secure by Design and address the technical debt. Bring systems up to current standards and levels of inspection and security. Address the need for security training for developers, threat modeling for all services, complete Code QL and Network Security.\\n\\n2. Create efficiency in current systems. Unify critical tools and systems, including the numerous Identity systems, SOC/IR, case management, and risk management. Create common tooling and mechanisms to ensure compliance with Secure by Default and Secure in Deployment.\\n\\n3. Future-proof the company, focusing on AI. We need to invest resources in how we identify the new risks (Secure by Design) and operate the environments (Secure by Default and Secure in Deployment). We will leverage AI to improve security operations and define the standards to ensure we build trust and transparency across all the customer facing implementations as well.\\n\\n| 23% |\\n|-----|\\n| annual rise in the cases processed by the Microsoft Security Response Center and Security Operations Center teams. |', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.611285698245899),\n",
       " NodeWithScore(node=TextNode(id_='252bd563-4787-49d4-838e-8aecb012558a', embedding=None, metadata={'file_path': 'msft_ddr.pdf', 'page_num': 99}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='# Responding with breakthrough innovation\\n\\n## Introduction from Bret Arsenault\\n\\nIn the last few months, the world has witnessed a wave of innovation as organizations apply advanced AI to new technologies and use cases. Our industry is facing a paradigm shift and taking a massive leap forward as technology advances incredibly quickly and makes daily headlines.\\n\\nThe security industry has been focused on managing increased risks and innovating to adapt to the fast pace of change. We continue to hear from our peers, partners, and customers that security has never been more critical to the resilience of business and society.\\n\\nThere has been significant growth in the threat landscape as more attackers use increasingly sophisticated techniques to compromise an ever-growing footprint of services, devices, and users. All combined, this creates a larger attack surface and threat potential than we have ever dealt with before. At Microsoft, we have seen a 23 percent annual rise in the cases processed by the Microsoft Security Response Center and Security Operations Center teams.\\n\\nWhile human ingenuity and expertise will always be a precious and irreplaceable component of cyber defense, technology has the potential to augment these unique capabilities with the skill sets, processing speeds, and rapid learning of modern AI. Technology can work alongside us, detect hidden patterns and behaviors, and inform a response at machine speed with the latest and most advanced security practices.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6088645775734907),\n",
       " NodeWithScore(node=TextNode(id_='ec7c83a9-c83b-4e99-b96d-6a486b70cac6', embedding=None, metadata={'file_path': 'msft_10k_2024.pdf', 'page_num': 55}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='NO_CONTENT_HERE', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6058475180108085),\n",
       " NodeWithScore(node=TextNode(id_='e5454990-0877-4869-b1a8-8c194434f53f', embedding=None, metadata={'file_path': 'msft_10k_2024.pdf', 'page_num': 18}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='PART I\\nItem 1\\n\\n# Search and News Advertising\\n\\nOur Search and news advertising business is designed to deliver relevant search, native, and display advertising to a global audience. Our Microsoft Edge browser and Bing Chat capabilities are key tools to enable user acquisition and engagement, while our technology platform enables accelerated delivery of digital advertising solutions. In addition to first-party tools, we have several partnerships with companies, such as Yahoo, through which we provide and monetize search offerings. Growth depends on our ability to attract new users, understand intent, and match intent with relevant content on advertising offerings.\\n\\n## Competition\\n\\nWindows faces competition from various software products and from alternative platforms and devices, mainly from Apple and Google. We believe Windows competes effectively by giving customers choice, value, flexibility, security, an easy-to-use interface, and compatibility with a broad range of hardware and software applications, including those that enable productivity.\\n\\nDevices face competition from various computer, tablet, and hardware manufacturers who offer a unique combination of high-quality industrial design and innovative technologies across various price points. These manufacturers, many of which are also current or potential partners and customers, include Apple and our Windows OEMs.\\n\\nXbox and our cloud gaming services face competition from various online gaming ecosystems and game streaming services, including those operated by Amazon, Apple, Meta, and Tencent. We also compete with other providers of entertainment services such as video streaming platforms. Our gaming platform competes with console platforms from Nintendo and Sony, both of which have a large, established base of customers. We believe our gaming platform is effectively positioned against, and uniquely differentiated from, competitive products and services based on significant innovation in hardware architecture, user interface, developer tools, online gaming and entertainment services, and continued strong exclusive content from our own first-party game franchises as well as other digital content offerings.\\n\\nOur Search and news advertising business competes with Google and a wide array of websites, social platforms like Meta, and portals that provide content and online offerings to end users.\\n\\n# OPERATIONS\\n\\nWe have regional operations service centers that support our operations, including customer contract and order processing, billing, credit and collections, information processing, and vendor management and logistics. The center in Ireland supports the African, Asia-Pacific, European, and Middle East regions, and the centers in Arlington, Virginia, Atlanta, Georgia, Charlotte, North Carolina, Fargo, North Dakota, Fort Lauderdale, Florida, Redmond, Washington, Reno, Nevada, and Puerto Rico support the American regions.\\n\\nIn addition to our operations centers, we also operate datacenters throughout each of these regions. We continue to identify and evaluate opportunities to expand our datacenter locations and increase our server capacity to meet the evolving needs of our customers, particularly given the growing demand for AI services. Our datacenters depend on the availability of permitted and buildable land, predictable energy, networking supplies, and servers, including graphics processing units (\"GPUs\") and other components.\\n\\nOur devices are primarily manufactured by third-party contract manufacturers. For the majority of our products, we have the ability to use other manufacturers if a current vendor becomes unavailable or unable to meet our requirements. However, some of our products contain certain components for which there are very few qualified suppliers. Extended disruptions at these suppliers could impact our ability to manufacture devices on time to meet consumer demand.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6049851078221491),\n",
       " NodeWithScore(node=TextNode(id_='e4a6b87d-b80a-4cab-83fa-e9de0a47ac6b', embedding=None, metadata={'file_path': 'msft_10k_2024.pdf', 'page_num': 4}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='NO_CONTENT_HERE', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6046270666618602)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TMP\n",
    "tmp_nodes = index.as_retriever(similarity_top_k=5).retrieve(\"hello\")\n",
    "tmp_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4446-c477-4261-9747-c5294b0a54e9",
   "metadata": {},
   "source": [
    "### Define Retrievers\n",
    "\n",
    "Define retrievers, one for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bbac9ab-e3e2-448f-9e74-ad995415fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from typing import List\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "DEFAULT_TOOL_DESCRIPTION = \"Retrieves a small set of relevant document chunks from the corpus.\"\n",
    "\n",
    "# function tools\n",
    "def generate_tool(file: str, description: str = DEFAULT_TOOL_DESCRIPTION):\n",
    "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(\n",
    "                key=\"file_path\", operator=FilterOperator.EQ, value=file\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    def chunk_retriever_fn(query: str) -> List[NodeWithScore]:\n",
    "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
    "        nodes = retriever.retrieve(query)\n",
    "        return nodes\n",
    "    \n",
    "    # define name as a function of the file\n",
    "    fn_name = Path(file).stem + \"_retrieve\"\n",
    "    \n",
    "    tool = FunctionTool.from_defaults(fn=chunk_retriever_fn, name=fn_name, description=description)\n",
    "    \n",
    "    return tool\n",
    "\n",
    "# generate tools \n",
    "tools = []\n",
    "for f in files:\n",
    "    tools.append(generate_tool(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9106c7d-8c43-4443-a192-94d5f3a54ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Retrieves a small set of relevant document chunks from the corpus.', name='azure_gov_retrieve', fn_schema=<class 'llama_index.core.tools.utils.azure_gov_retrieve'>, return_direct=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f44305e5-c3e5-4835-8274-cfd5eb63de59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp = tools[0](\"test\").raw_output\n",
    "# len(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebbad-3200-4818-aa48-705eda21503e",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "\n",
    "The user specifies an RFP document as input. \n",
    "\n",
    "Let's build a workflow that can iterate through the extracted keys/questions from the RFP, and fill them out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc2c0d0-415d-4568-936b-a8c07bf629ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 7959a846-fa1c-4e8e-a984-b6389320cf6c\n",
      "......."
     ]
    }
   ],
   "source": [
    "rfp_docs = parser.load_data(Path(data_dir) / \"jedi_cloud_rfp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "740535e8-714b-4744-a515-5007834eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "import logging\n",
    "import json\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# this is the research agent's system prompt, tasked with answering a specific question\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
    "You are given a specific form key/question. Think step-by-step and use the existing set of tools to help answer the question.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the prompt tasked with extracting information from an RFP file. \n",
    "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
    "You are provided an entire RFP document, or a large subsection from it. \n",
    "\n",
    "We wish to generate a response to the RFP in a way that adheres to the instructions within the RFP, \\\n",
    "including the specific sections that an RFP response should contain, and the content that would need to go \\\n",
    "into each section.\n",
    "\n",
    "Your task is to extract out a list of \"questions\", where each question corresponds to a specific section that is required in the RFP response.\n",
    "Put another way, after we extract out the questions we will go through each question and answer each one \\\n",
    "with our downstream research assistant, and the combined\n",
    "question:answer pairs will constitute the full RFP response.\n",
    "\n",
    "- Make sure the questions are comprehensive and adheres to the RFP requirements.\n",
    "- Make sure each question is descriptive - this gives our downstream assistant context to fill out the value for that question \n",
    "- Extract out all the questions as a list of strings.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class OutputQuestions(BaseModel):\n",
    "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class OutputTemplateEvent(Event):\n",
    "    docs: List[Document]\n",
    "\n",
    "\n",
    "class QuestionsExtractedEvent(Event):\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class HandleQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class QuestionAnsweredEvent(Event):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "class CollectedAnswersEvent(Event):\n",
    "    combined_answers: str\n",
    "    \n",
    "\n",
    "class RFPWorkflow(Workflow):\n",
    "    \"\"\"RFP workflow.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tools,\n",
    "        parser: LlamaParse,\n",
    "        llm: LLM | None = None,\n",
    "        similarity_top_k: int = 20,\n",
    "        output_dir: str = \"data_out_rfp\",\n",
    "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.tools = tools\n",
    "        \n",
    "        self.parser = parser\n",
    "        \n",
    "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # initialize a Function Calling \"research\" agent where given a task, it can pull responses from relevant tools \n",
    "        self.research_agent = FunctionCallingAgentWorker.from_tools(\n",
    "            tools, llm=llm, verbose=True, system_prompt=agent_system_prompt\n",
    "        ).as_agent()\n",
    "        \n",
    "        # if not exists, create\n",
    "        out_path = Path(self.output_dir) / \"workflow_output\"\n",
    "        if not out_path.exists():\n",
    "            out_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    @step\n",
    "    async def parse_output_template(self, ctx: Context, ev: StartEvent) -> OutputTemplateEvent:\n",
    "        # load output template file \n",
    "        out_template_path = Path(f\"{self.output_dir}/workflow_output/output_template.jsonl\")\n",
    "        if out_template_path.exists():\n",
    "            with open(out_template_path, \"r\") as f:\n",
    "                docs = [Document.parse_obj(json.loads(line)) for line in f]\n",
    "        else:\n",
    "            docs = await self.parser.aload_data(ev.rfp_template_path)\n",
    "            # save output template to file\n",
    "            with open(out_template_path, \"w\") as f:\n",
    "                for doc in docs:\n",
    "                    f.write(doc.model_dump_json())\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "        await ctx.set(\"output_template\", docs)\n",
    "        return OutputTemplateEvent(docs=docs)\n",
    "    \n",
    "    @step\n",
    "    async def extract_questions(self, ctx: Context, ev: OutputTemplateEvent) -> HandleQuestionEvent:\n",
    "        docs = ev.docs\n",
    "        \n",
    "        # save all_questions to file\n",
    "        out_keys_path = Path(f\"{self.output_dir}/workflow_output/all_keys.txt\")\n",
    "        if out_keys_path.exists():\n",
    "            with open(out_keys_path, \"r\") as f:\n",
    "                output_qs = [q.strip() for q in f.readlines()]\n",
    "        else:\n",
    "             # try stuffing all text into the prompt\n",
    "            all_text = \"\\n\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
    "            prompt = PromptTemplate(template=EXTRACT_KEYS_PROMPT)\n",
    "\n",
    "            try: \n",
    "                output_qs = self.llm.structured_predict(\n",
    "                    OutputQuestions, prompt, context=all_text\n",
    "                ).questions\n",
    "            except Exception as e:\n",
    "                _logger.error(f\"Error extracting questions from page: {all_text}\")\n",
    "                _logger.error(e)\n",
    "                \n",
    "            with open(out_keys_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(output_qs))\n",
    "        \n",
    "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
    "\n",
    "        for question in output_qs:\n",
    "            ctx.send_event(HandleQuestionEvent(question=question))\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @step\n",
    "    async def handle_question(self, ev: HandleQuestionEvent) -> QuestionAnsweredEvent:\n",
    "        question = ev.question\n",
    "        \n",
    "        # ensure the agent's memory is cleared \n",
    "        self.research_agent.reset()\n",
    "        response = self.research_agent.query(question)\n",
    "        \n",
    "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(self, ctx: Context, ev: QuestionAnsweredEvent) -> CollectedAnswersEvent:\n",
    "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
    "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "        \n",
    "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
    "        # save combined_answers to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/combined_answers.json\", \"w\") as f:\n",
    "            f.write(combined_answers)\n",
    "\n",
    "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
    "\n",
    "    @step\n",
    "    async def generate_output(self, ctx: Context, ev: CollectedAnswersEvent) -> StopEvent:\n",
    "        output_template = await ctx.get(\"output_template\")\n",
    "        output_template = \"\\n\".join([doc.get_content('none') for doc in output_template])\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=GENERATE_OUTPUT_PROMPT,\n",
    "        )\n",
    "        final_output = self.llm.predict(prompt, output_template=output_template, answers=ev.combined_answers)\n",
    "        # save final_output to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
    "            f.write(final_output)\n",
    "\n",
    "        return StopEvent(result=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b895c3b1-6ea1-41c3-bcf9-e42c2a4beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "workflow = RFPWorkflow(\n",
    "    tools,\n",
    "    parser=parser,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    timeout=60.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ab2465b-62f7-4afc-bc18-6ab3fbe5bfad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_output_template\n",
      "Step parse_output_template produced event OutputTemplateEvent\n",
      "Running step extract_questions\n",
      "Step extract_questions produced no event\n",
      "Running step handle_question\n",
      "Added user message to memory: What is the overall project scope and objectives as outlined in the RFP?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"overall project scope and objectives RFP\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that I couldn't find any specific information regarding the overall project scope and objectives outlined in the RFP. If you have access to the RFP document, you might want to check the sections typically titled \"Project Scope\" or \"Objectives\" for detailed information. Alternatively, if you provide me with more context or specific details, I can assist you further.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the specific deliverables required for this project?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"specific deliverables required for this project\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that there is no specific information available regarding the deliverables required for the project. You may need to provide more context or check other sources for this information.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What is the timeline for the project, including key milestones and deadlines?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"project timeline key milestones deadlines\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "I couldn't find specific information regarding the timeline for the project, including key milestones and deadlines. If you have any additional context or details about the project, I can help you further.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the qualifications and experience required for the project team members?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"qualifications and experience required for project team members\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that there is no specific information available regarding the qualifications and experience required for project team members in the provided context. If you have any other questions or need information on a different topic, feel free to ask!\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What is the budget range for the project, and what are the payment terms?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"budget range for the project\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"payment terms for the project\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that there is no specific information available regarding the budget range for the project or the payment terms. If you have any other questions or need assistance with a different topic, feel free to ask!\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the evaluation criteria that will be used to assess proposals?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"evaluation criteria for proposals\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"criteria for assessing proposals\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"proposal evaluation criteria\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"how proposals are evaluated\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "I couldn't find specific information regarding the evaluation criteria for assessing proposals. If you have a particular context or document in mind, please provide more details, and I can assist you further.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the specific requirements for project management and reporting?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"requirements for project management and reporting\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"project management requirements\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"reporting requirements in project management\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that I couldn't find specific information regarding the requirements for project management and reporting in the available context. However, I can provide a general overview based on common practices:\n",
      "\n",
      "### Project Management Requirements:\n",
      "1. **Project Charter**: A document that outlines the project objectives, scope, stakeholders, and overall goals.\n",
      "2. **Project Plan**: A detailed plan that includes timelines, resources, budget, and risk management strategies.\n",
      "3. **Stakeholder Engagement**: Identifying and engaging stakeholders throughout the project lifecycle.\n",
      "4. **Resource Allocation**: Ensuring that the necessary resources (human, financial, and material) are available and allocated effectively.\n",
      "5. **Risk Management**: Identifying potential risks and developing mitigation strategies.\n",
      "6. **Communication Plan**: Establishing how information will be communicated among stakeholders.\n",
      "\n",
      "### Reporting Requirements:\n",
      "1. **Progress Reports**: Regular updates on project status, including milestones achieved and any issues encountered.\n",
      "2. **Financial Reports**: Tracking budget expenditures and forecasting future financial needs.\n",
      "3. **Performance Metrics**: Defining key performance indicators (KPIs) to measure project success.\n",
      "4. **Final Report**: A comprehensive report at the end of the project summarizing outcomes, lessons learned, and recommendations for future projects.\n",
      "\n",
      "If you need more specific information or have a particular context in mind, please let me know!\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the expectations for communication and collaboration with the client?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"expectations for communication and collaboration with the client\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that there is no specific information available regarding the expectations for communication and collaboration with the client in the provided context. However, generally, expectations for communication and collaboration with clients typically include:\n",
      "\n",
      "1. **Regular Updates**: Keeping the client informed about progress, challenges, and milestones.\n",
      "2. **Clear Communication**: Ensuring that all communication is clear, concise, and professional.\n",
      "3. **Feedback Mechanisms**: Establishing channels for the client to provide feedback and ask questions.\n",
      "4. **Collaboration Tools**: Utilizing tools that facilitate collaboration, such as project management software or shared documents.\n",
      "5. **Scheduled Meetings**: Setting up regular meetings to discuss project status and any issues that may arise.\n",
      "6. **Responsiveness**: Being prompt in responding to client inquiries and concerns.\n",
      "\n",
      "If you need more specific details or have a particular context in mind, please provide additional information.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the risks associated with the project, and how will they be managed?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"risks associated with the project and management strategies\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that there is no specific information available regarding the risks associated with the project and their management strategies in the provided context. If you have any specific details or aspects of the project in mind, please share them, and I can help you analyze potential risks and management approaches.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      "Added user message to memory: What are the terms and conditions related to confidentiality and data protection?\n",
      "=== Calling Function ===\n",
      "Calling function: chunk_retriever_fn with args: {\"query\": \"terms and conditions confidentiality data protection\"}\n",
      "=== Function Output ===\n",
      "[]\n",
      "=== LLM Response ===\n",
      "It seems that I couldn't find specific information regarding the terms and conditions related to confidentiality and data protection in the available context. If you have a specific document or source in mind, please provide more details, and I can assist you further.\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Running step combine_answers\n",
      "Step combine_answers produced event CollectedAnswersEvent\n",
      "Running step generate_output\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run the agent\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m workflow\u001b[38;5;241m.\u001b[39mrun(rfp_template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(Path(data_dir) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjedi_cloud_rfp.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(response))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/asyncio/futures.py:285\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/asyncio/futures.py:196\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[1;32m    195\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "response = await workflow.run(rfp_template_path=str(Path(data_dir) / \"jedi_cloud_rfp.pdf\"))\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a14dc-423f-43fa-94c2-3668e5e76fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de346256-766d-42c2-8fb4-87dcf4707dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99548c-72f7-4651-8396-20bdd455447b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_parse",
   "language": "python",
   "name": "llama_parse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
