{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ae9bad-b8cc-43de-ba7d-387e0155674c",
   "metadata": {},
   "source": [
    "# Multimodal Report Generation Agent \n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/multimodal/multimodal_report_generation_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this cookbook we show you how to build a multimodal report generation agent from a bank of research reports. We use the a set of ICLR papers (which were also used as the dataset in our [DeepLearning.ai course](https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=llamaindexC2-launch&utm_medium=headband&utm_source=dlai-homepage).\n",
    "\n",
    "We use our workflow abstraction to define an agentic system that first performs research to pull in the relevant files, and then surfaces it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8d9a7-5036-4d32-818f-00b2e888521f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccdd53-e68a-4199-aacb-cfe71ad1ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c5556-a789-4386-a1ee-cce01dbeb6cf",
   "metadata": {},
   "source": [
    "### Setup Observability\n",
    "\n",
    "We setup an integration with LlamaTrace (integration with Arize).\n",
    "\n",
    "If you haven't already done so, make sure to create an account here: https://llamatrace.com/login. Then create an API key and put it in the `PHOENIX_API_KEY` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabee1f-290a-4c85-b362-54f45c8559ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U llama-index-callbacks-arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb245c-730b-4c34-ad68-708fdde0e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import llama_index.core\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = \"<PHOENIX_API_KEY>\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ba6b0-51af-42f9-b1b2-8d3e721ef782",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Setup\n",
    "\n",
    "Setup models that will be used for downstream orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2071d-bbc2-4707-8ae7-cb4e1fecafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb362db-b1b1-4eea-be1a-b1f78b0779d7",
   "metadata": {},
   "source": [
    "## Load, Parse, and Index Research Papers\n",
    "\n",
    "Here we load 11 popular ICLR 2024 papers, and then we parse through LlamaParse.\n",
    "\n",
    "**NOTE**: this may be slow. To save your results, run the cell to save all your outputs to JSON, so you can reload instead of having to re-parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bce3407-a7d2-47e8-9eaf-ab297a94750c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
    "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
    "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
    "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
    "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
    "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
    "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
    "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
    "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
    "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
    "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    \"metagpt.pdf\",\n",
    "    \"longlora.pdf\",\n",
    "    \"loftq.pdf\",\n",
    "    \"swebench.pdf\",\n",
    "    \"selfrag.pdf\",\n",
    "    \"zipformer.pdf\",\n",
    "    \"values.pdf\",\n",
    "    \"finetune_fair_diffusion.pdf\",\n",
    "    \"knowledge_card.pdf\",\n",
    "    \"metra.pdf\",\n",
    "    \"vr_mcl.pdf\"\n",
    "]\n",
    "\n",
    "data_dir = \"iclr_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d93b9c0-a343-4873-92de-60d8af2260f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: iclr_docs: File exists\n",
      "--2024-08-09 22:41:21--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16911937 (16M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/metagpt.pdf’\n",
      "\n",
      "iclr_docs/metagpt.p 100%[===================>]  16.13M  24.5MB/s    in 0.7s    \n",
      "\n",
      "2024-08-09 22:41:22 (24.5 MB/s) - ‘iclr_docs/metagpt.pdf’ saved [16911937/16911937]\n",
      "\n",
      "--2024-08-09 22:41:22--  https://openreview.net/pdf?id=6PmJoRfdaK\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1168720 (1.1M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/longlora.pdf’\n",
      "\n",
      "iclr_docs/longlora. 100%[===================>]   1.11M  3.99MB/s    in 0.3s    \n",
      "\n",
      "2024-08-09 22:41:23 (3.99 MB/s) - ‘iclr_docs/longlora.pdf’ saved [1168720/1168720]\n",
      "\n",
      "--2024-08-09 22:41:23--  https://openreview.net/pdf?id=LzPWWPAdY4\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 366134 (358K) [application/pdf]\n",
      "Saving to: ‘iclr_docs/loftq.pdf’\n",
      "\n",
      "iclr_docs/loftq.pdf 100%[===================>] 357.55K  2.04MB/s    in 0.2s    \n",
      "\n",
      "2024-08-09 22:41:24 (2.04 MB/s) - ‘iclr_docs/loftq.pdf’ saved [366134/366134]\n",
      "\n",
      "--2024-08-09 22:41:24--  https://openreview.net/pdf?id=VTF8yNQM66\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2680380 (2.6M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/swebench.pdf’\n",
      "\n",
      "iclr_docs/swebench. 100%[===================>]   2.56M  7.49MB/s    in 0.3s    \n",
      "\n",
      "2024-08-09 22:41:25 (7.49 MB/s) - ‘iclr_docs/swebench.pdf’ saved [2680380/2680380]\n",
      "\n",
      "--2024-08-09 22:41:25--  https://openreview.net/pdf?id=hSyW5go0v8\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1244749 (1.2M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/selfrag.pdf’\n",
      "\n",
      "iclr_docs/selfrag.p 100%[===================>]   1.19M  4.30MB/s    in 0.3s    \n",
      "\n",
      "2024-08-09 22:41:26 (4.30 MB/s) - ‘iclr_docs/selfrag.pdf’ saved [1244749/1244749]\n",
      "\n",
      "--2024-08-09 22:41:26--  https://openreview.net/pdf?id=9WD9KwssyT\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 511626 (500K) [application/pdf]\n",
      "Saving to: ‘iclr_docs/zipformer.pdf’\n",
      "\n",
      "iclr_docs/zipformer 100%[===================>] 499.63K  2.22MB/s    in 0.2s    \n",
      "\n",
      "2024-08-09 22:41:26 (2.22 MB/s) - ‘iclr_docs/zipformer.pdf’ saved [511626/511626]\n",
      "\n",
      "--2024-08-09 22:41:27--  https://openreview.net/pdf?id=yV6fD7LYkF\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4171982 (4.0M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/values.pdf’\n",
      "\n",
      "iclr_docs/values.pd 100%[===================>]   3.98M  10.2MB/s    in 0.4s    \n",
      "\n",
      "2024-08-09 22:41:27 (10.2 MB/s) - ‘iclr_docs/values.pdf’ saved [4171982/4171982]\n",
      "\n",
      "--2024-08-09 22:41:28--  https://openreview.net/pdf?id=hnrB5YHoYu\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34710410 (33M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/finetune_fair_diffusion.pdf’\n",
      "\n",
      "iclr_docs/finetune_ 100%[===================>]  33.10M  32.3MB/s    in 1.0s    \n",
      "\n",
      "2024-08-09 22:41:29 (32.3 MB/s) - ‘iclr_docs/finetune_fair_diffusion.pdf’ saved [34710410/34710410]\n",
      "\n",
      "--2024-08-09 22:41:29--  https://openreview.net/pdf?id=WbWtOYIzIK\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 877083 (857K) [application/pdf]\n",
      "Saving to: ‘iclr_docs/knowledge_card.pdf’\n",
      "\n",
      "iclr_docs/knowledge 100%[===================>] 856.53K  3.57MB/s    in 0.2s    \n",
      "\n",
      "2024-08-09 22:41:30 (3.57 MB/s) - ‘iclr_docs/knowledge_card.pdf’ saved [877083/877083]\n",
      "\n",
      "--2024-08-09 22:41:30--  https://openreview.net/pdf?id=c5pwL0Soay\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4775879 (4.6M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/metra.pdf’\n",
      "\n",
      "iclr_docs/metra.pdf 100%[===================>]   4.55M  11.3MB/s    in 0.4s    \n",
      "\n",
      "2024-08-09 22:41:31 (11.3 MB/s) - ‘iclr_docs/metra.pdf’ saved [4775879/4775879]\n",
      "\n",
      "--2024-08-09 22:41:31--  https://openreview.net/pdf?id=TpD2aG1h0D\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1973959 (1.9M) [application/pdf]\n",
      "Saving to: ‘iclr_docs/vr_mcl.pdf’\n",
      "\n",
      "iclr_docs/vr_mcl.pd 100%[===================>]   1.88M  5.72MB/s    in 0.3s    \n",
      "\n",
      "2024-08-09 22:41:32 (5.72 MB/s) - ‘iclr_docs/vr_mcl.pdf’ saved [1973959/1973959]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"{data_dir}\"\n",
    "for url, paper in zip(urls, papers):\n",
    "    !wget \"{url}\" -O \"{data_dir}/{paper}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fa3bd-c70f-45d5-9377-d81be8160891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"anthropic-sonnet-3.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee54b5-b423-4b43-930c-ea941723ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# delete and recreate the image directory if not already created \n",
    "out_image_dir = \"out_iclr_images\"\n",
    "!rm -rf \"{out_image_dir}\"\n",
    "!mkdir \"{out_image_dir}\"\n",
    "\n",
    "\n",
    "paper_dicts = {}\n",
    "\n",
    "for paper_path in papers:\n",
    "    paper_base = Path(paper_path).basename\n",
    "    full_paper_path = str(Path(data_dir) / paper_path)\n",
    "    print(paper_base)\n",
    "    raise Exception\n",
    "    md_json_objs = parser.get_json_result(full_paper_path)\n",
    "    json_dicts = md_json_objs[0][\"pages\"]\n",
    "    \n",
    "    image_path = str(Path(out_image_dir) / paper_base)\n",
    "    image_dicts = parser.get_images(md_json_objs, download_path=image_path)\n",
    "    paper_dicts[paper_path] = {\n",
    "        \"paper_path\": full_paper_path,\n",
    "        \"json_dicts\": json_dicts,\n",
    "        \"image_path\": image_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae2dee-9d85-4604-8a51-705d4db527f7",
   "metadata": {},
   "source": [
    "#### Get Text Nodes\n",
    "\n",
    "Convert the dictionary above into TextNode objects that we can put into a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c24174-05ce-417f-8dd2-79c3f375db03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e331dfe-a627-4e23-8c57-70ab1d9342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: these are utility functions to sort the dumped images by the page number\n",
    "# (they are formatted like \"{uuid}-{page_num}.jpg\"\n",
    "import re\n",
    "\n",
    "\n",
    "def get_page_number(file_name):\n",
    "    match = re.search(r\"-page-(\\d+)\\.jpg$\", str(file_name))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "def _get_sorted_image_files(image_dir):\n",
    "    \"\"\"Get image files sorted by page.\"\"\"\n",
    "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file()]\n",
    "    sorted_files = sorted(raw_files, key=get_page_number)\n",
    "    return sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fe5ef-171e-4a54-9084-7a7805103a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "# attach image metadata to the text nodes\n",
    "def get_text_nodes(json_dicts, paper_path, image_dir=None):\n",
    "    \"\"\"Split docs into nodes, by separator.\"\"\"\n",
    "    nodes = []\n",
    "\n",
    "    image_files = _get_sorted_image_files(image_dir) if image_dir is not None else None\n",
    "    md_texts = [d[\"md\"] for d in json_dicts]\n",
    "\n",
    "    for idx, md_text in enumerate(md_texts):\n",
    "        chunk_metadata = {\n",
    "            \"page_num\": idx + 1, \n",
    "            \"parsed_text_markdown\": md_text,\n",
    "            \"paper_path\": paper_path\n",
    "        }\n",
    "        if image_files is not None:\n",
    "            image_file = image_files[idx]\n",
    "            chunk_metadata[\"image_path\"] = str(image_file)\n",
    "        chunk_metadata[\"parsed_text_markdown\"] = md_text\n",
    "        node = TextNode(\n",
    "            text=\"\",\n",
    "            metadata=chunk_metadata,\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591669c-5a8e-491d-9cef-0b754abbf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will combine all nodes from all papers into a single list \n",
    "all_text_nodes = []\n",
    "for paper_path, paper_dict in paper_dicts.items():\n",
    "    json_dicts = paper_dict[\"json_dicts\"]\n",
    "    text_nodes = get_text_nodes(json_dicts, paper_dict[\"paper_path\"], image_dir=paper_dict[\"image_path\"])\n",
    "    all_text_nodes.extend(text_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c13950-c1db-435f-b5b4-89d62b8b7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_num: 11\n",
      "image_path: data_images/412ac275-abe2-4585-be43-5680e7754740-page-10.jpg\n",
      "parsed_text_markdown: # Commitment to Disciplined Reinvestment Rate\n",
      "\n",
      "Disciplined Reinvestment Rate is the Foundation for Superior Returns on and of Capital, while Driving Durable CFO Growth\n",
      "\n",
      "| Metric | Value |\n",
      "|--------|-------|\n",
      "| 10-Year Reinvestment Rate | ~50% |\n",
      "| CFO CAGR 2024-2032 | ~6% |\n",
      "| Mid-Cycle Planning Price | at $60/BBL WTI |\n",
      "\n",
      "| Period | Industry Growth Focus | ConocoPhillips Strategy Reset | Reinvestment Rate |\n",
      "|--------|------------------------|-------------------------------|-------------------|\n",
      "| 2012-2016 | >100% Reinvestment Rate | - | ~$75/BBL WTI Average |\n",
      "| 2017-2022 | - | <60% Reinvestment Rate | ~$63/BBL WTI Average |\n",
      "| 2023E | - | - | at $80/BBL WTI |\n",
      "| 2024-2028 | - | - | at $60/BBL WTI (with $80/BBL WTI option shown) |\n",
      "| 2029-2032 | - | - | at $60/BBL WTI (with $80/BBL WTI option shown) |\n",
      "\n",
      "*Chart shows ConocoPhillips Average Annual Reinvestment Rate (%) over time, with historic rates in grey and projected rates in blue.*\n",
      "\n",
      "Reinvestment rate and cash from operations (CFO) are non-GAAP measures. Definitions and reconciliations are included in the Appendix.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_nodes[10].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f404f56-db1e-4ed7-9ba1-ead763546348",
   "metadata": {},
   "source": [
    "### Build Indexes\n",
    "\n",
    "Once the text nodes are ready, we feed into our vector store index abstraction, which will index these nodes into a simple in-memory vector store (of course, you should definitely check out our 40+ vector store integrations!)\n",
    "\n",
    "Besides vector indexing, we **also** store a mapping of paper path to the summary index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7bc2e-be3d-4fd3-a1df-b2dcaa66c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    SummaryIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"storage_nodes_papers\"):\n",
    "    index = SummaryIndex(text_nodes)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"summary_index\")\n",
    "    index.storage_context.persist(\"./storage_nodes_papers\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"storage_nodes_papers\"\n",
    "    )\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"summary_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bebde3-015b-48b9-81f1-264ee6426a41",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "We define two tools for the downstream agent: a vector search tool and a summarization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f4dcb-e569-47d7-8d35-19bc6f5ba12f",
   "metadata": {},
   "source": [
    "## Build Workflow \n",
    "\n",
    "Now that we've built the index, we're ready to build the report generation workflow. \n",
    "\n",
    "The workflow contains roughly the following steps: \n",
    "\n",
    "1. **Research Gathering**: Perform a function calling loop where the agent tries to reason about what tool to call (chunk-level or document-level retrieval) in order to gather more information. All information is shared to a dictionary that is propagated throughout each step. The tools return an indication of the type of information returned to the agent. After the agent feels like it's gathered enough information, move on to the next phase.\n",
    "\n",
    "\n",
    "2. **Report Generation**: Generate a research report given the pooled research. For now, try to stuff as much information into the context window through the summary index.\n",
    "\n",
    "\n",
    "This implementation is inspired by our [Function Calling Agent workflow](https://docs.llamaindex.ai/en/latest/examples/workflow/function_calling_agent/) implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa654a0-4c43-48e3-85d1-b1796445fe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Workflow\n",
    "\n",
    "from typing import Any, List\n",
    "\n",
    "from llama_index.core.llms.function_calling import FunctionCallingLLM\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.tools.types import BaseTool\n",
    "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, step\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine\n",
    "\n",
    "\n",
    "class ReportGenerationAgent(Workflow):\n",
    "    \"\"\"Report generation agent.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        llm: FunctionCallingLLM | None = None,\n",
    "        tools: List[BaseTool] | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tools = tools or []\n",
    "\n",
    "        self.llm = llm or OpenAI()\n",
    "        self.summarizer = CompactAndRefine(llm=self.llm)\n",
    "        assert self.llm.metadata.is_function_calling_model\n",
    "\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(llm=llm)\n",
    "        self.sources = []\n",
    "\n",
    "    @step()\n",
    "    async def prepare_chat_history(self, ev: StartEvent) -> InputEvent:\n",
    "        # clear sources\n",
    "        self.sources = []\n",
    "\n",
    "        # get user input\n",
    "        user_input = ev.input\n",
    "        user_msg = ChatMessage(role=\"user\", content=user_input)\n",
    "        self.memory.put(user_msg)\n",
    "\n",
    "        # get chat history\n",
    "        chat_history = self.memory.get()\n",
    "        return InputEvent(input=chat_history)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def handle_llm_input(\n",
    "        self, ctx: Context, ev: InputEvent\n",
    "    ) -> ChunkRetrievalEvent | DocRetrievalEvent | StopEvent:\n",
    "        chat_history = ev.input\n",
    "\n",
    "        response = await self.llm.achat_with_tools(\n",
    "            self.tools, chat_history=chat_history\n",
    "        )\n",
    "        self.memory.put(response.message)\n",
    "\n",
    "        tool_calls = self.llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "        if not tool_calls:\n",
    "            # all the content should be stored in the context, so just pass along input \n",
    "            return ReportGenerationEvent(input=ev.input)\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.tool_name == \"chunk_retrieval\":\n",
    "                return ChunkRetrievalEvent(query=tool_call.tool_kwargs[\"query_str\"])\n",
    "            elif tool_call.tool_name == \"doc_retrieval\":\n",
    "                return DocRetrievalEvent(query=tool_call.tool_kwargs[\"query_str\"])\n",
    "            else:\n",
    "                return StopEvent(result={\"response\": \"Invalid tool.\"})\n",
    "\n",
    "        # if not tool_calls:\n",
    "        #     return StopEvent(\n",
    "        #         result={\"response\": response, \"sources\": [*self.sources]}\n",
    "        #     )\n",
    "        # else:\n",
    "        #     return ToolCallEvent(tool_calls=tool_calls)\n",
    "        \n",
    "    @step(pass_context=True)\n",
    "    async def handle_retrieval(self, ctx: Context, ev: ChunkRetrievalEvent | DocRetrievalEvent) -> InputEvent:\n",
    "        \"\"\"Handle retrieval.\n",
    "        \n",
    "        Store retrieved chunks, and go back to agent reasoning loop.\n",
    "        \n",
    "        \"\"\"\n",
    "        if isinstance(ev, ChunkRetrievalEvent):\n",
    "            retrieved_chunks = self.chunk_retriever_tool(ev.query).raw_output\n",
    "        else:\n",
    "            retrieved_chunks = self.doc_retriever_tool(ev.query).raw_output\n",
    "        ctx.data[\"stored_chunks\"].extend(retrieved_chunks)\n",
    "        \n",
    "        # synthesize an answer given the query to return to the LLM.\n",
    "        response = self.summarizer.synthesize(ev.query, nodes=retrieved_chunks)\n",
    "        self.memory.put(str(response))\n",
    "        \n",
    "        # send input event back with updated chat history\n",
    "        return InputEvent(input=self.memory.get())\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def generate_report(self, ctx: Context, ev: ReportGenerationEvent) -> StopEvent:\n",
    "        \"\"\"Generate report.\"\"\"\n",
    "        # given all the context, generate query\n",
    "        self.summarizer.synthesize(ev.query, nodes=ctx[\"stored_chunks\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v3",
   "language": "python",
   "name": "llama_index_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
